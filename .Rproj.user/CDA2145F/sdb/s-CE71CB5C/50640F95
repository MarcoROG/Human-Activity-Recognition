{
    "contents" : "library(caret)\n#Set a seed for coherent tests\nset.seed(12345)\n\n#Load datasets\ntraining = read.csv(\"Data/pml-training.csv\", header = TRUE)\nfinalTest = read.csv(\"Data/pml-testing.csv\", header = TRUE)\n\n##########################################################################################\n#########################          GENERIC PREPROCESSING         #########################\n##########################################################################################\n#> Remove some useless predictors\n#> Factorize 'Classe'\n#> Set NULL or Empty values to NA\n\n#Remove useless columns which can only lead to overfitting\n#The time of the day in which an exercise is performed cannot influence the quality of its execution\n#X is the order in which the sample was measured, this should not influence the quality either\n#The name will not influence it either along with window information\ntoDrop = c(\"user_name\",\"X\",\"raw_timestamp_part_1\",\"raw_timestamp_part_2\",\"cvtd_timestamp\",\"new_window\",\"num_window\")\ntraining = training [,!(names(training) %in% toDrop) ]\nfinalTest = finalTest [,!(names(finalTest) %in% toDrop)]\n\n#Convert training-set's \"Classe\" column to factor variable\ntraining[,\"classe\"] = as.factor(training[,\"classe\"])\n\n#Set null or empty values to NA\nis.na(training[,]) <- training[,names(training)] == \"\"\nis.na(training[,]) <- training[,names(training)] == \"NULL\"\n\n##########################################################################################\n#########################          DATA PARTITIONING         #############################\n##########################################################################################\n#>Split datasets in order to have a test, a training and a finalTest sets\n\n#Split the training set with 60-40\ntrainIndexes <- createDataPartition(training$classe, p = .6,list = FALSE)\n#Remove \"classe\" since this should be treated as a test set, so without labels\ntest <- training[-trainIndexes,]\ntraining <- training[trainIndexes,]\n#Clean RAM\nrm(trainIndexes)\n\n##########################################################################################\n#################          TrainingSet-Specific PREPROCESSING         ####################\n##########################################################################################\n#>Remove columns with too many NA values (this would cause imperfect knn) from all the sets\n# but perform the analisys only on the training set, in order to avoid fitting our model in the\n# evalutation sets aswell.\n\n#Find all the columns with less than 50% NA values\ntraining <- training[,(colSums(is.na(training[,names(training)])) / nrow(training) ) < 0.5]\n#Save this for later removing the same vars from the test set aswell\ntoKeep <- names(training)\ntest <- test [, toKeep]\ntoKeepTest <- toKeep[toKeep !=\"classe\"]\n#Keep the same variables, since we have to always use the same model\nfinalTest <- finalTest[,toKeepTest]\n\n\n#Create a preprocessing object using the training set\n#PCA and NZV were considered but they wouldn't be usefull in this case\n\n#Extract everything except the solution\ntr <- training[,!(colnames(training)==\"classe\")] \n#Preprocess\npreprocessing <- preProcess(tr,method=c(\"knnImpute\",\"center\",\"scale\"))\n#Save the solutions for the training set\nclasse <- training$classe\n#Clear memory\nrm(training)\n#Reassign the training set with the labels\ntraining <- predict(preprocessing,newdata=tr)\ntraining$classe <- classe\n#Remove the temporary variables\nrm(tr)\nrm(classe)\n\n#>Preprocess the test sets\nte <- test[,!(colnames(test)==\"classe\")]\nclasse <- test$classe\nrm(test)\ntest <- predict(preprocessing,newdata=te)\ntest$classe <- classe\n\nfinalTest <- predict(preprocessing,newdata=finalTest)\n\n#Remove the temporary variables\nrm(te)\nrm(classe)\n\n#Create a validation set, it's done here so that we can avoid doing the preprocessing one more time\ntestIndexes <- createDataPartition(test$classe, p = .75,list = FALSE) #Keep 75% in test set cause we need it to train our combining predictor\nvalidation <- test[-testIndexes,]\ntest <- test[testIndexes,]\nrm(testIndexes)\n\n##########################################################################################\n############################          MODEL FITTING         ##############################\n##########################################################################################\n\n#Training controller\ntrainControl <- trainControl(method = \"repeatedcv\", number = 5,  repeats = 3)\n\n#We're going to fit multiple models, maybe just a RF model would have been enough, but this is a nice practice\n#for predicting with more than one model, which was in the scope of the course.\n\n#Fit a NN algorithm\nNN <- train(training$classe ~ ., data=as.data.frame(training), method=\"multinom\",trainControl=trainControl, allowParallel=TRUE, verbose=FALSE)\n#Fit an SVM, one of the most advanced algorithms\nSVM <- train (training$classe ~ .,data=training,method=\"svmLinear\",trainControl=trainControl,allowParallel=TRUE, verbose=FALSE)\n#Fit a random forest, for its ability to detect usefull features and correlations\nRF <- train(training$classe ~ ., data=training, method=\"rf\", trainControl=trainControl,allowParallel=TRUE, verbose=FALSE)\n\n##########################################################################################\n##########################          MODEL EVALUTATION         ############################\n##########################################################################################\nSVMpredict <- predict(SVM, newdata=test)\nSVMaccuracy <- confusionMatrix(SVMpredict,test$classe)$overall['Accuracy']\nSVMaccuracy\n\nRFpredict <- predict(RF, newdata=test)\nRFaccuracy <- confusionMatrix(RFpredict,test$classe)$overall['Accuracy']\nRFaccuracy\n\nNNpredict <- predict(NN, newdata=test)\nNNaccuracy <- confusionMatrix(NNpredict,test$classe)$overall['Accuracy']\nNNaccuracy\n\n##########################################################################################\n##########################          MODEL COMBINING         ##############################\n##########################################################################################\n\n#Combine the predictors\ncombinedPredictors <- data.frame(SVMpredict,RFpredict,NNpredict,test$classe)\n#Train a predictor\ncombinedModel <- train(combinedPredictors$test.classe ~ ., data= combinedPredictors, method = \"nb\")\n\n#Predict for validation\nSVMpredict <- predict(SVM, newdata= validation)\nRFpredict <- predict(RF, newdata= validation)\nNNpredict <- predict(NN, newdata= validation)\n\n#Combine the data\ncombinedPredictors <- data.frame(SVMpredict,RFpredict,NNpredict)\ncombinedPredictors$test.classe <- validation$classe\n\n#Make it predict for evalutation\ncombinedPrediction <- predict(combinedModel,newdata=combinedPredictors)\ncombinedAccuracy <- confusionMatrix(combinedPrediction,validation$classe)$overall['Accuracy']\ncombinedAccuracy\n\n##########################################################################################\n##########################          FINAL PREDICTION         #############################\n##########################################################################################\n\nrm(SVMpredict)\nrm(RFpredict)\nrm(NNpredict)\n\n#Measure time to see how long it takes\nstartTime<- proc.time()\n\nSVMpredict <- predict(SVM, newdata=finalTest)\nRFpredict <- predict(RF, newdata= finalTest)\nNNpredict <- predict(NN, newdata= finalTest)\n\nfinalCombinedData<- data.frame(SVMpredict,RFpredict,NNpredict)\n\noutCome <- predict(combinedModel, finalCombinedData)\n\nproc.time() - startTime\n\noutCome\n\n##########################################################################################\n#############################          SAVE FILES         ################################\n##########################################################################################\n\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"Data/problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\n#pml_write_files(outCome)",
    "created" : 1442414124609.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3539023631",
    "id" : "50640F95",
    "lastKnownWriteTime" : 1443110556,
    "path" : "C:/Users/Marco/Desktop/R/CourseProject/Main.R",
    "project_path" : "Main.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}