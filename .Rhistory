library(caret)
#Set a seed for coherent tests
set.seed(12345)
#Load datasets
training = read.csv("../pml-training.csv", header = TRUE)
finalTest = read.csv("../pml-testing.csv", header = TRUE)
##########################################################################################
#########################          GENERIC PREPROCESSING         #########################
##########################################################################################
#> Remove some useless predictors
#> Factorize 'Classe'
#> Set NULL or Empty values to NA
#Remove useless columns which can only lead to overfitting
#The time of the day in which an exercise is performed cannot influence the quality of its execution
#X is the order in which the sample was measured, this should not influence the quality either
#The name will not influence it either along with window information
toDrop = c("user_name","X","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
training = training [,!(names(training) %in% toDrop) ]
finalTest = finalTest [,!(names(finalTest) %in% toDrop)]
#Convert training-set's "Classe" column to factor variable
training[,"classe"] = as.factor(training[,"classe"])
#Set null or empty values to NA
is.na(training[,]) <- training[,names(training)] == ""
is.na(training[,]) <- training[,names(training)] == "NULL"
##########################################################################################
#########################          DATA PARTITIONING         #############################
##########################################################################################
#>Split datasets in order to have a test, a training and a finalTest sets
#Split the training set with 60-40
trainIndexes <- createDataPartition(training$classe, p = .6,list = FALSE)
#Remove "classe" since this should be treated as a test set, so without labels
test <- training[-trainIndexes,]
#Save the solutions for later use on confusionMatrix
testTruth <- test$classe
test <- test[,test != "classe"]
training <- training[trainIndexes,]
#Clean RAM
rm(trainIndexes)
##########################################################################################
#################          TrainingSet-Specific PREPROCESSING         ####################
##########################################################################################
#>Remove columns with too many NA values (this would cause imperfect knn) from all the sets
# but perform the analisys only on the training set, in order to avoid fitting our model in the
# evalutation sets aswell.
#Find all the columns with less than 50% NA values
training <- training[,(colSums(is.na(training[,names(training)])) / nrow(training) ) < 0.5]
#Save this for later removing the same vars from the test set aswell
toKeep <- names(training)
toKeepTest <- toKeep[toKeep !="classe"]
#Keep the same variables, since we have to always use the same model
test <- test [, toKeepTest]
finalTest <- finalTest[,toKeepTest]
#Create a preprocessing object using the training set
#PCA and NZV were considered but they wouldn't be usefull in this case
#Extract everything except the solution
tr <- training[,!(colnames(training)=="classe")]
#Preprocess
preprocessing <- preProcess(tr,method=c("knnImpute","center","scale"))
#Save the solutions for the training set
classe <- training$classe
#Clear memory
rm(training)
#Reassign the training set with the labels
training <- predict(preprocessing,newdata=tr)
training$classe <- classe
#Remove the temporary variable
rm(tr)
#Preprocess the test sets
test <- predict(preprocessing,newdata=test)
finalTest <- predict(preprocessing,newdata=finalTest)
GBM <- train(classe ~ ., data=training,tuneLength=1, method="nnet", verbose=TRUE)
GBM <- train(classe ~ ., data=training,tuneLength=1, method="elm", verbose=TRUE)
GBM <- train(classe ~ ., data=training, method="elm", verbose=TRUE)
rm(list=ls())
library(caret)
#Set a seed for coherent tests
set.seed(12345)
#Load datasets
training = read.csv("../pml-training.csv", header = TRUE)
finalTest = read.csv("../pml-testing.csv", header = TRUE)
##########################################################################################
#########################          GENERIC PREPROCESSING         #########################
##########################################################################################
#> Remove some useless predictors
#> Factorize 'Classe'
#> Set NULL or Empty values to NA
#Remove useless columns which can only lead to overfitting
#The time of the day in which an exercise is performed cannot influence the quality of its execution
#X is the order in which the sample was measured, this should not influence the quality either
#The name will not influence it either along with window information
toDrop = c("user_name","X","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
training = training [,!(names(training) %in% toDrop) ]
finalTest = finalTest [,!(names(finalTest) %in% toDrop)]
#Convert training-set's "Classe" column to factor variable
training[,"classe"] = as.factor(training[,"classe"])
#Set null or empty values to NA
is.na(training[,]) <- training[,names(training)] == ""
is.na(training[,]) <- training[,names(training)] == "NULL"
##########################################################################################
#########################          DATA PARTITIONING         #############################
##########################################################################################
#>Split datasets in order to have a test, a training and a finalTest sets
#Split the training set with 60-40
trainIndexes <- createDataPartition(training$classe, p = .6,list = FALSE)
#Remove "classe" since this should be treated as a test set, so without labels
test <- training[-trainIndexes,]
#Save the solutions for later use on confusionMatrix
testTruth <- test$classe
test <- test[,test != "classe"]
training <- training[trainIndexes,]
#Clean RAM
rm(trainIndexes)
##########################################################################################
#################          TrainingSet-Specific PREPROCESSING         ####################
##########################################################################################
#>Remove columns with too many NA values (this would cause imperfect knn) from all the sets
# but perform the analisys only on the training set, in order to avoid fitting our model in the
# evalutation sets aswell.
#Find all the columns with less than 50% NA values
training <- training[,(colSums(is.na(training[,names(training)])) / nrow(training) ) < 0.5]
#Save this for later removing the same vars from the test set aswell
toKeep <- names(training)
toKeepTest <- toKeep[toKeep !="classe"]
#Keep the same variables, since we have to always use the same model
test <- test [, toKeepTest]
finalTest <- finalTest[,toKeepTest]
#Create a preprocessing object using the training set
#PCA and NZV were considered but they wouldn't be usefull in this case
#Extract everything except the solution
tr <- training[,!(colnames(training)=="classe")]
#Preprocess
preprocessing <- preProcess(tr,method=c("knnImpute","center","scale"))
#Save the solutions for the training set
classe <- training$classe
#Clear memory
rm(training)
#Reassign the training set with the labels
training <- predict(preprocessing,newdata=tr)
training$classe <- classe
#Remove the temporary variable
rm(tr)
#Preprocess the test sets
test <- predict(preprocessing,newdata=test)
finalTest <- predict(preprocessing,newdata=finalTest)
##########################################################################################
############################          MODEL FITTING         ##############################
##########################################################################################
#Training controller
trainControl <- trainControl(method = "repeatedcv", number = 3,  repeats = 1)
#We're going to fit multiple models, maybe just a RF model would have been enough, but this is a nice practice
#for predicting with more than one model, which was in the scope of the course.
#Fit an ELM NN algorithm
ELM <- train(training$classe ~ ., data=training, method="elm",trainControl=trainControl, verbose=FALSE)
#Fit an SVM, one of the most advanced algorithms
SVM <- train (training$classe ~ .,data=training,method="svmLinear",trainControl=trainControl, verbose=FALSE)
#Fit a random forest, for its ability to detect usefull features and correlations
RF <- train(training$classe ~ ., data=training, method="rf", trainControl=trainControl, verbose=FALSE)
rm(list=ls())
library(caret)
#Set a seed for coherent tests
set.seed(12345)
#Load datasets
training = read.csv("../pml-training.csv", header = TRUE)
finalTest = read.csv("../pml-testing.csv", header = TRUE)
##########################################################################################
#########################          GENERIC PREPROCESSING         #########################
##########################################################################################
#> Remove some useless predictors
#> Factorize 'Classe'
#> Set NULL or Empty values to NA
#Remove useless columns which can only lead to overfitting
#The time of the day in which an exercise is performed cannot influence the quality of its execution
#X is the order in which the sample was measured, this should not influence the quality either
#The name will not influence it either along with window information
toDrop = c("user_name","X","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
training = training [,!(names(training) %in% toDrop) ]
finalTest = finalTest [,!(names(finalTest) %in% toDrop)]
#Convert training-set's "Classe" column to factor variable
training[,"classe"] = as.factor(training[,"classe"])
#Set null or empty values to NA
is.na(training[,]) <- training[,names(training)] == ""
is.na(training[,]) <- training[,names(training)] == "NULL"
##########################################################################################
#########################          DATA PARTITIONING         #############################
##########################################################################################
#>Split datasets in order to have a test, a training and a finalTest sets
#Split the training set with 60-40
trainIndexes <- createDataPartition(training$classe, p = .6,list = FALSE)
#Remove "classe" since this should be treated as a test set, so without labels
test <- training[-trainIndexes,]
#Save the solutions for later use on confusionMatrix
testTruth <- test$classe
test <- test[,test != "classe"]
training <- training[trainIndexes,]
#Clean RAM
rm(trainIndexes)
##########################################################################################
#################          TrainingSet-Specific PREPROCESSING         ####################
##########################################################################################
#>Remove columns with too many NA values (this would cause imperfect knn) from all the sets
# but perform the analisys only on the training set, in order to avoid fitting our model in the
# evalutation sets aswell.
#Find all the columns with less than 50% NA values
training <- training[,(colSums(is.na(training[,names(training)])) / nrow(training) ) < 0.5]
#Save this for later removing the same vars from the test set aswell
toKeep <- names(training)
toKeepTest <- toKeep[toKeep !="classe"]
#Keep the same variables, since we have to always use the same model
test <- test [, toKeepTest]
finalTest <- finalTest[,toKeepTest]
#Create a preprocessing object using the training set
#PCA and NZV were considered but they wouldn't be usefull in this case
#Extract everything except the solution
tr <- training[,!(colnames(training)=="classe")]
#Preprocess
preprocessing <- preProcess(tr,method=c("knnImpute","center","scale"))
#Save the solutions for the training set
classe <- training$classe
#Clear memory
rm(training)
#Reassign the training set with the labels
training <- predict(preprocessing,newdata=tr)
training$classe <- classe
#Remove the temporary variable
rm(tr)
#Preprocess the test sets
test <- predict(preprocessing,newdata=test)
finalTest <- predict(preprocessing,newdata=finalTest)
##########################################################################################
############################          MODEL FITTING         ##############################
##########################################################################################
#Training controller
trainControl <- trainControl(method = "repeatedcv", number = 3,  repeats = 1)
#We're going to fit multiple models, maybe just a RF model would have been enough, but this is a nice practice
#for predicting with more than one model, which was in the scope of the course.
#Fit an ELM NN algorithm
ELM <- train(training$classe ~ ., data=training, method="elm",trainControl=trainControl, allowParallel=TRUE, verbose=FALSE)
#Fit an SVM, one of the most advanced algorithms
SVM <- train (training$classe ~ .,data=training,method="svmLinear",trainControl=trainControl,allowParallel=TRUE, verbose=FALSE)
#Fit a random forest, for its ability to detect usefull features and correlations
RF <- train(training$classe ~ ., data=training, method="rf", trainControl=trainControl,allowParallel=TRUE, verbose=FALSE)
##########################################################################################
##########################          MODEL EVALUTATION         ############################
##########################################################################################
SVMpredict <- predict(SVM, newdata=test)
SVMaccuracy <- confusionMatrix(SVMpredict,testTruth)$overall['Accuracy']
RFpredict <- predict(RF, newdata=test)
RFaccuracy <- confusionMatrix(RFpredict,testTruth)$overall['Accuracy']
ELMpredict <- predict(ELM, newdata=test)
ELMaccuracy <- confusionMatrix(GBMpredict,testTruth)$overall['Accuracy']
##########################################################################################
##########################          MODEL COMBINING         ##############################
##########################################################################################
#Combine the predictors
combinedPredictors <- data.frame(SVMpredict,RFpredict,ELMpredict,testTruth)
#Train a predictor
combinedModel <- train(testTruth ~ ., data= combinedPredictors, method = "gam")
##########################################################################################
##########################          FINAL PREDICTION         #############################
##########################################################################################
rm(SVMpredict)
rm(RFpredict)
rm(ELMpredict)
SVMpredict <- predict(SVM, newdata=finalTest)
RFpredict <- predict(RF, newdata= finalTest)
ELMpredict <- predict(ELM, newdata= finalTest)
finalCombinedData<- data.frame(SVMpredict,RFpredict,ELMpredict)
outCome <- predict(combinedModel, finalCombinedData)
SVMaccuracy
RFaccuracy
outCome
SVMpredict
ELMpredict
RFpredict
##########################################################################################
##########################          MODEL EVALUTATION         ############################
##########################################################################################
SVMpredict <- predict(SVM, newdata=test)
SVMaccuracy <- confusionMatrix(SVMpredict,testTruth)$overall['Accuracy']
RFpredict <- predict(RF, newdata=test)
RFaccuracy <- confusionMatrix(RFpredict,testTruth)$overall['Accuracy']
ELMpredict <- predict(ELM, newdata=test)
ELMaccuracy <- confusionMatrix(ELMpredict,testTruth)$overall['Accuracy']
##########################################################################################
##########################          MODEL COMBINING         ##############################
##########################################################################################
#Combine the predictors
combinedPredictors <- data.frame(SVMpredict,RFpredict,ELMpredict,testTruth)
#Train a predictor
combinedModel <- train(testTruth ~ ., data= combinedPredictors, method = "gbm")
SVMpredict <- predict(SVM, newdata=test)
SVMaccuracy <- confusionMatrix(SVMpredict,testTruth)$overall['Accuracy']
RFpredict <- predict(RF, newdata=test)
RFaccuracy <- confusionMatrix(RFpredict,testTruth)$overall['Accuracy']
ELMpredict <- predict(ELM, newdata=test)
ELMaccuracy <- confusionMatrix(ELMpredict,testTruth)$overall['Accuracy']
##########################################################################################
##########################          MODEL COMBINING         ##############################
##########################################################################################
#Combine the predictors
combinedPredictors <- data.frame(SVMpredict,RFpredict,ELMpredict,testTruth)
#Train a predictor
combinedModel <- train(testTruth ~ ., data= combinedPredictors, method = "nb")
##########################################################################################
##########################          FINAL PREDICTION         #############################
##########################################################################################
rm(SVMpredict)
rm(RFpredict)
rm(ELMpredict)
SVMpredict <- predict(SVM, newdata=finalTest)
RFpredict <- predict(RF, newdata= finalTest)
ELMpredict <- predict(ELM, newdata= finalTest)
finalCombinedData<- data.frame(SVMpredict,RFpredict,ELMpredict)
outCome <- predict(combinedModel, finalCombinedData)
install.packages("combinat")
install.packages("klaR")
SVMpredict <- predict(SVM, newdata=test)
SVMaccuracy <- confusionMatrix(SVMpredict,testTruth)$overall['Accuracy']
RFpredict <- predict(RF, newdata=test)
RFaccuracy <- confusionMatrix(RFpredict,testTruth)$overall['Accuracy']
ELMpredict <- predict(ELM, newdata=test)
ELMaccuracy <- confusionMatrix(ELMpredict,testTruth)$overall['Accuracy']
##########################################################################################
##########################          MODEL COMBINING         ##############################
##########################################################################################
#Combine the predictors
combinedPredictors <- data.frame(SVMpredict,RFpredict,ELMpredict,testTruth)
#Train a predictor
combinedModel <- train(testTruth ~ ., data= combinedPredictors, method = "nb")
##########################################################################################
##########################          FINAL PREDICTION         #############################
##########################################################################################
rm(SVMpredict)
rm(RFpredict)
rm(ELMpredict)
SVMpredict <- predict(SVM, newdata=finalTest)
RFpredict <- predict(RF, newdata= finalTest)
ELMpredict <- predict(ELM, newdata= finalTest)
finalCombinedData<- data.frame(SVMpredict,RFpredict,ELMpredict)
outCome <- predict(combinedModel, finalCombinedData)
warnings()
outCome
SVMpredict <- predict(SVM, newdata=test)
SVMaccuracy <- confusionMatrix(SVMpredict,testTruth)$overall['Accuracy']
RFpredict <- predict(RF, newdata=test)
RFaccuracy <- confusionMatrix(RFpredict,testTruth)$overall['Accuracy']
ELMpredict <- predict(ELM, newdata=test)
ELMaccuracy <- confusionMatrix(ELMpredict,testTruth)$overall['Accuracy']
##########################################################################################
##########################          MODEL COMBINING         ##############################
##########################################################################################
#Combine the predictors
combinedPredictors <- data.frame(SVMpredict,RFpredict,ELMpredict,testTruth)
#Train a predictor
combinedModel <- train(testTruth ~ ., data= combinedPredictors, method = "nb")
##########################################################################################
##########################          FINAL PREDICTION         #############################
##########################################################################################
rm(SVMpredict)
rm(RFpredict)
rm(ELMpredict)
#Measure time to see how long it takes
startTime<- proc.time()
SVMpredict <- predict(SVM, newdata=finalTest)
RFpredict <- predict(RF, newdata= finalTest)
ELMpredict <- predict(ELM, newdata= finalTest)
finalCombinedData<- data.frame(SVMpredict,RFpredict,ELMpredict)
outCome <- predict(combinedModel, finalCombinedData)
proc.time() - startTime
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(outCome)
outCome
